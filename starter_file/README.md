*NOTE:* This file is a template that you can use to create the README for your project. The *TODO* comments below will highlight the information you should be sure to include.

# Employee Churn Rate Problem

*TODO:* Write a short introduction to your project.

A company concerned about the growth in the attrition rate of its employees has asked us to carry out a predictive analysis to be able to anticipate possible future abandonments. So that at the end of the project, you know which group of employees your talent retention efforts focused on.

To carry out this project, I used two tools that Azure ML provide us to train Machine Learning models: Azure Hyperdrive and Azure AutoML. Then, I deployed the best model generated by both methods and consumed the model endpoint to provide some predictions.

The steps followed in the project are summarized in the following diagram:

![capstone_diagram](./screenshots/capstone-diagram.png)

## Project Set Up and Installation
*OPTIONAL:* If your project has any special installation steps, this is where you should put it. To turn this project into a professional portfolio project, you are encouraged to explain how to set up this project in AzureML.



## Dataset

### Overview
*TODO*: Explain about the data you are using and where you got it from.

For this project the company have given us the file `HR Dataset`, which can download be downloaded from the following link: https://raw.githubusercontent.com/aiplanethub/Datasets/master/HR_comma_sep.csv. The file contains the following variables:

  * **satisfaccion_nivel :** It is the level of employee satisfaction, which takes values between 0-1.
  * **last_ Evaluation :** Employee's preformance evaluation. Values between 0-1.
  * **number_projects :** How many projects are asigned to thar employee?
  * **average_monthly_hours :** How many average hours does an employee work in a month?
  * **time_spent_company :** Employee experience. Number of years an employee has been in the company.
  * **work_accident :** Whether an employee has had a work accident or not.
  * **Promotion_last_5years :** Whether an employee has had a promotion in the last 5 years or not.
  * **sales :** Department/division to which the employee belongs.
  * **salary :** Salary level of the employee (low, medium or high).
  * **left :** Whether the employee has left the company or not (0: No, 1: Yes).


The variable to predict (target) is `left` and the rest can be used as explanatory variables for the study. A sample of the data is as follows:




### Task
*TODO*: Explain the task you are going to be solving with this dataset and the features you will be using for it.

The aim of this project is to develop a machine learning model that can predict whether an employee is going to leave the company or not. Therefore, the target variable is the variable `left`. Since it can take just to possible values, we have to perform a classification task. 

A sample of the data is as follows:

![data_sample](./screenshots/data_sample.png)

### Access
*TODO*: Explain how you are accessing the data in your workspace.

The way I uploaded the dataset to the AzureML environment, was using the following piece of code that you can find in the Jupyter Notebooks `automl.ipynb` and `hyperparameter_tuning.ipynb`.

```ruby
ws = Workspace.from_config()

# choose a name for experiment
experiment_name = 'automl_experiment'
project_folder = './pipeline-project'

experiment=Experiment(ws, experiment_name)



#Source of the data: https://raw.githubusercontent.com/aiplanethub/Datasets/master/HR_comma_sep.csv
# We first check if the data is already loaded inthe Workspace. Otherwise, create it from the file

found = False
key = "HR Dataset"
description_text = "HR Dataset for capstone project"

if key in ws.datasets.keys(): 
        found = True
        dataset = ws.datasets[key] 

if not found:
        # Create AML Dataset and register it into Workspace
        example_data = 'https://raw.githubusercontent.com/aiplanethub/Datasets/master/HR_comma_sep.csv'
        dataset = Dataset.Tabular.from_delimited_files(example_data)        
        #Register Dataset in Workspace
        dataset = dataset.register(workspace=ws,
                                   name=key,
                                   description=description_text)


df = dataset.to_pandas_dataframe()
```

In this code we defined a variable that includes the workspace definition. Then we check whether the dataset is already uploaded to the AzureML platform, and if that is not the case we upload it.

Once the dataset is uploaded into AzureML, you can find it in the `Data` section of the platform:

![Dataset_v1](./screenshots/registered_dataset.PNG)

We can get a sample of the dataset using the `Explore` window.

![Dataset_v2](./screenshots/registered_dataset_v2.PNG)

## Automated ML
*TODO*: Give an overview of the `automl` settings and configuration you used for this experiment

In the following piece of code, I include the AutoML configuration that I have chosen for this experiment.

```ruby
automl_settings = {
    "experiment_timeout_minutes": 20,
    "max_concurrent_iterations": 5,
    "primary_metric" : 'AUC_weighted'
}

# TODO: Put your automl config here
automl_config = AutoMLConfig(compute_target=cpu_cluster,
                             task = "classification",
                             training_data=dataset,
                             label_column_name="left",   
                             path = project_folder,
                             enable_early_stopping= True,
                             featurization= 'auto',
                             debug_log = "automl_errors.log",
                             **automl_settings
                            )

```




### Results
*TODO*: What are the results you got with your automated ML model? What were the parameters of the model? How could you have improved it?

*TODO* Remeber to provide screenshots of the `RunDetails` widget as well as a screenshot of the best model trained with it's parameters.

The best performing model form the AutoML process is a Voting Ensemble.

![Best_model](./screenshots/TrainingRuns_AutoML.PNG)

![Best_model_register](./screenshots/Best_model_register.PNG)

![RunDetails_autoML](./screenshots/RunDetails_autoML.PNG)

![Best_model_metrics](./screenshots/Model_metrics.PNG)

## Hyperparameter Tuning
*TODO*: What kind of model did you choose for this experiment and why? Give an overview of the types of parameters and their ranges used for the hyperparameter search

In the following piece of code, I include the HyperDrive configuration that I have chosen for this experiment.


```ruby
from azureml.train.hyperdrive.policy import BanditPolicy
from azureml.train.hyperdrive.sampling import RandomParameterSampling
import numpy as np

# Early termination policy
early_termination_policy = BanditPolicy(slack_factor = 0.1, 
                                        evaluation_interval = 2,
                                        delay_evaluation = 10)


#Parameter sampling definition
param_sampling = RandomParameterSampling( {
    "--C" : uniform(0.0,10.0),
    "--max_iter" : choice(10,20,30,40,50,60,70,80,90,100)
    }
)



estimator = ScriptRunConfig(source_directory='.',
                            command=['python', 'train.py'],
                            compute_target=cluster_name,
                            environment=sklearn_env)

hyperdrive_run_config = HyperDriveConfig(run_config=estimator, 
                             hyperparameter_sampling=param_sampling,
                             policy=early_termination_policy,
                             primary_metric_name='Accuracy',
                             primary_metric_goal= PrimaryMetricGoal.MAXIMIZE,
                             max_total_runs = 4,
                             max_concurrent_runs = 2)
```

### Results
*TODO*: What are the results you got with your model? What were the parameters of the model? How could you have improved it?

![Hyperdrive_model_results](./screenshots/Hyperdrive_model_results.PNG)

*TODO* Remeber to provide screenshots of the `RunDetails` widget as well as a screenshot of the best model trained with it's parameters.
[HyperDrive_model](./screenshots/HyperDrive_model_registration.PNG)

## Model Deployment
*TODO*: Give an overview of the deployed model and instructions on how to query the endpoint with a sample input.

![App_Insights](./screenshots/App_Insights_logs.PNG)

![App_Insights_best_model](./screenshots/Best_model_appInsights.PNG)

![Best_model_id](./screenshots/Best_model_id.PNG)

![Model_deploy_v1](./screenshots/Best_model_endpoint.PNG)

![Model_deploy_success](./screenshots/Best_model_endpoint_success.PNG)




## Screen Recording
*TODO* Provide a link to a screen recording of the project in action. Remember that the screencast should demonstrate:
- A working model
- Demo of the deployed  model
- Demo of a sample request sent to the endpoint and its response

[Youtube_video](https://youtu.be/NHvwtG6lIeE?feature=shared&t=33)

## Standout Suggestions
*TODO (Optional):* This is where you can provide information about any standout suggestions that you have attempted.
