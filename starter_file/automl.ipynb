{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Model\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.51.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1696090076195
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696092001742
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'automl_experiment'\n",
        "project_folder = './pipeline-project'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1696090077593
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Source of the data: https://raw.githubusercontent.com/aiplanethub/Datasets/master/HR_comma_sep.csv\n",
        "\n",
        "# We first check if the data is already loaded inthe Workspace. Otherwise, create it from the file\n",
        "\n",
        "found = False\n",
        "key = \"HR Dataset\"\n",
        "description_text = \"HR Dataset for capstone project\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        dataset = ws.datasets[key] \n",
        "\n",
        "if not found:\n",
        "        # Create AML Dataset and register it into Workspace\n",
        "        example_data = 'https://raw.githubusercontent.com/aiplanethub/Datasets/master/HR_comma_sep.csv'\n",
        "        dataset = Dataset.Tabular.from_delimited_files(example_data)        \n",
        "        #Register Dataset in Workspace\n",
        "        dataset = dataset.register(workspace=ws,\n",
        "                                   name=key,\n",
        "                                   description=description_text)\n",
        "\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "       satisfaction_level  last_evaluation  number_project  \\\ncount        14999.000000     14999.000000    14999.000000   \nmean             0.612834         0.716102        3.803054   \nstd              0.248631         0.171169        1.232592   \nmin              0.090000         0.360000        2.000000   \n25%              0.440000         0.560000        3.000000   \n50%              0.640000         0.720000        4.000000   \n75%              0.820000         0.870000        5.000000   \nmax              1.000000         1.000000        7.000000   \n\n       average_montly_hours  time_spend_company  Work_accident          left  \\\ncount          14999.000000        14999.000000   14999.000000  14999.000000   \nmean             201.050337            3.498233       0.144610      0.238083   \nstd               49.943099            1.460136       0.351719      0.425924   \nmin               96.000000            2.000000       0.000000      0.000000   \n25%              156.000000            3.000000       0.000000      0.000000   \n50%              200.000000            3.000000       0.000000      0.000000   \n75%              245.000000            4.000000       0.000000      0.000000   \nmax              310.000000           10.000000       1.000000      1.000000   \n\n       promotion_last_5years  \ncount           14999.000000  \nmean                0.021268  \nstd                 0.144281  \nmin                 0.000000  \n25%                 0.000000  \n50%                 0.000000  \n75%                 0.000000  \nmax                 1.000000  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_montly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>left</th>\n      <th>promotion_last_5years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n      <td>14999.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.612834</td>\n      <td>0.716102</td>\n      <td>3.803054</td>\n      <td>201.050337</td>\n      <td>3.498233</td>\n      <td>0.144610</td>\n      <td>0.238083</td>\n      <td>0.021268</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.248631</td>\n      <td>0.171169</td>\n      <td>1.232592</td>\n      <td>49.943099</td>\n      <td>1.460136</td>\n      <td>0.351719</td>\n      <td>0.425924</td>\n      <td>0.144281</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.090000</td>\n      <td>0.360000</td>\n      <td>2.000000</td>\n      <td>96.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.440000</td>\n      <td>0.560000</td>\n      <td>3.000000</td>\n      <td>156.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.640000</td>\n      <td>0.720000</td>\n      <td>4.000000</td>\n      <td>200.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.820000</td>\n      <td>0.870000</td>\n      <td>5.000000</td>\n      <td>245.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>7.000000</td>\n      <td>310.000000</td>\n      <td>10.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1696090085793
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n0                0.38             0.53               2                   157   \n1                0.80             0.86               5                   262   \n2                0.11             0.88               7                   272   \n3                0.72             0.87               5                   223   \n4                0.37             0.52               2                   159   \n\n   time_spend_company  Work_accident  left  promotion_last_5years Department  \\\n0                   3              0     1                      0      sales   \n1                   6              0     1                      0      sales   \n2                   4              0     1                      0      sales   \n3                   5              0     1                      0      sales   \n4                   3              0     1                      0      sales   \n\n   salary  \n0     low  \n1  medium  \n2  medium  \n3     low  \n4     low  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_montly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>left</th>\n      <th>promotion_last_5years</th>\n      <th>Department</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.38</td>\n      <td>0.53</td>\n      <td>2</td>\n      <td>157</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.80</td>\n      <td>0.86</td>\n      <td>5</td>\n      <td>262</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.11</td>\n      <td>0.88</td>\n      <td>7</td>\n      <td>272</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.72</td>\n      <td>0.87</td>\n      <td>5</td>\n      <td>223</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.37</td>\n      <td>0.52</td>\n      <td>2</td>\n      <td>159</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1696090125796
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.take(5).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n0                0.38             0.53               2                   157   \n1                0.80             0.86               5                   262   \n2                0.11             0.88               7                   272   \n3                0.72             0.87               5                   223   \n4                0.37             0.52               2                   159   \n\n   time_spend_company  Work_accident  left  promotion_last_5years Department  \\\n0                   3              0     1                      0      sales   \n1                   6              0     1                      0      sales   \n2                   4              0     1                      0      sales   \n3                   5              0     1                      0      sales   \n4                   3              0     1                      0      sales   \n\n   salary  \n0     low  \n1  medium  \n2  medium  \n3     low  \n4     low  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>satisfaction_level</th>\n      <th>last_evaluation</th>\n      <th>number_project</th>\n      <th>average_montly_hours</th>\n      <th>time_spend_company</th>\n      <th>Work_accident</th>\n      <th>left</th>\n      <th>promotion_last_5years</th>\n      <th>Department</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.38</td>\n      <td>0.53</td>\n      <td>2</td>\n      <td>157</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.80</td>\n      <td>0.86</td>\n      <td>5</td>\n      <td>262</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.11</td>\n      <td>0.88</td>\n      <td>7</td>\n      <td>272</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>medium</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.72</td>\n      <td>0.87</td>\n      <td>5</td>\n      <td>223</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.37</td>\n      <td>0.52</td>\n      <td>2</td>\n      <td>159</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>sales</td>\n      <td>low</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696090150076
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Cluster creation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"cluster-udacity\"\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster in the provided workspace, so we use it.')\n",
        "except ComputeTargetException:\n",
        "    comp_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=3)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cluster_name, comp_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress..\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1696090168573
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 20,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'AUC_weighted'\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(compute_target=cpu_cluster,\n",
        "                             task = \"classification\",\n",
        "                             training_data=dataset,\n",
        "                             label_column_name=\"left\",   \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1696090189422
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl_experiment</td><td>AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-242066/workspaces/quick-starts-ws-242066&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1696090195653
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(remote_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3f93e2ad011460eb49cb1856ac264f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-242066/workspaces/quick-starts-ws-242066&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a\", \"run_properties\": {\"run_id\": \"AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a\", \"created_utc\": \"2023-09-30T16:09:54.246655Z\", \"properties\": {\"num_iterations\": \"1000\", \"training_type\": \"TrainFull\", \"acquisition_function\": \"EI\", \"primary_metric\": \"AUC_weighted\", \"train_split\": \"0\", \"acquisition_parameter\": \"0\", \"num_cross_validation\": null, \"target\": \"cluster-udacity\", \"AMLSettingsJsonString\": \"{\\\"path\\\":null,\\\"name\\\":\\\"automl_experiment\\\",\\\"subscription_id\\\":\\\"d7f39349-a66b-446e-aba6-0053c2cf1c11\\\",\\\"resource_group\\\":\\\"aml-quickstarts-242066\\\",\\\"workspace_name\\\":\\\"quick-starts-ws-242066\\\",\\\"region\\\":\\\"southcentralus\\\",\\\"compute_target\\\":\\\"cluster-udacity\\\",\\\"spark_service\\\":null,\\\"azure_service\\\":\\\"remote\\\",\\\"many_models\\\":false,\\\"pipeline_fetch_max_batch_size\\\":1,\\\"enable_batch_run\\\":true,\\\"enable_parallel_run\\\":false,\\\"num_procs\\\":null,\\\"enable_run_restructure\\\":false,\\\"start_auxiliary_runs_before_parent_complete\\\":false,\\\"enable_code_generation\\\":true,\\\"iterations\\\":1000,\\\"primary_metric\\\":\\\"AUC_weighted\\\",\\\"task_type\\\":\\\"classification\\\",\\\"positive_label\\\":null,\\\"data_script\\\":null,\\\"test_size\\\":0.0,\\\"test_include_predictions_only\\\":false,\\\"validation_size\\\":0.0,\\\"n_cross_validations\\\":null,\\\"y_min\\\":null,\\\"y_max\\\":null,\\\"num_classes\\\":null,\\\"featurization\\\":\\\"auto\\\",\\\"_ignore_package_version_incompatibilities\\\":false,\\\"is_timeseries\\\":false,\\\"max_cores_per_iteration\\\":1,\\\"max_concurrent_iterations\\\":5,\\\"iteration_timeout_minutes\\\":null,\\\"mem_in_mb\\\":null,\\\"enforce_time_on_windows\\\":false,\\\"experiment_timeout_minutes\\\":20,\\\"experiment_exit_score\\\":null,\\\"partition_column_names\\\":null,\\\"whitelist_models\\\":null,\\\"blacklist_algos\\\":[\\\"TensorFlowLinearClassifier\\\",\\\"TensorFlowDNN\\\"],\\\"supported_models\\\":[\\\"LogisticRegression\\\",\\\"MultinomialNaiveBayes\\\",\\\"TensorFlowLinearClassifier\\\",\\\"BernoulliNaiveBayes\\\",\\\"RandomForest\\\",\\\"LightGBM\\\",\\\"SGD\\\",\\\"DecisionTree\\\",\\\"XGBoostClassifier\\\",\\\"KNN\\\",\\\"TabnetClassifier\\\",\\\"ExtremeRandomTrees\\\",\\\"GradientBoosting\\\",\\\"LinearSVM\\\",\\\"AveragedPerceptronClassifier\\\",\\\"TensorFlowDNN\\\",\\\"SVM\\\"],\\\"private_models\\\":[],\\\"auto_blacklist\\\":true,\\\"blacklist_samples_reached\\\":false,\\\"exclude_nan_labels\\\":true,\\\"verbosity\\\":20,\\\"_debug_log\\\":\\\"azureml_automl.log\\\",\\\"show_warnings\\\":false,\\\"model_explainability\\\":true,\\\"service_url\\\":null,\\\"sdk_url\\\":null,\\\"sdk_packages\\\":null,\\\"enable_onnx_compatible_models\\\":false,\\\"enable_split_onnx_featurizer_estimator_models\\\":false,\\\"vm_type\\\":\\\"STANDARD_D2_V2\\\",\\\"telemetry_verbosity\\\":20,\\\"send_telemetry\\\":true,\\\"enable_dnn\\\":false,\\\"scenario\\\":\\\"AutoML\\\",\\\"environment_label\\\":null,\\\"save_mlflow\\\":false,\\\"enable_categorical_indicators\\\":false,\\\"force_text_dnn\\\":false,\\\"enable_feature_sweeping\\\":true,\\\"enable_early_stopping\\\":true,\\\"early_stopping_n_iters\\\":10,\\\"arguments\\\":null,\\\"dataset_id\\\":\\\"386f569b-55e5-476a-b65d-2f5a5a0b3a51\\\",\\\"hyperdrive_config\\\":null,\\\"validation_dataset_id\\\":null,\\\"run_source\\\":null,\\\"metrics\\\":null,\\\"enable_metric_confidence\\\":false,\\\"enable_ensembling\\\":true,\\\"enable_stack_ensembling\\\":true,\\\"ensemble_iterations\\\":15,\\\"enable_tf\\\":false,\\\"enable_subsampling\\\":null,\\\"subsample_seed\\\":null,\\\"enable_nimbusml\\\":false,\\\"enable_streaming\\\":false,\\\"force_streaming\\\":false,\\\"track_child_runs\\\":true,\\\"n_best_runs\\\":1,\\\"allowed_private_models\\\":[],\\\"label_column_name\\\":\\\"left\\\",\\\"weight_column_name\\\":null,\\\"cv_split_column_names\\\":null,\\\"enable_local_managed\\\":false,\\\"_local_managed_run_id\\\":null,\\\"cost_mode\\\":1,\\\"lag_length\\\":0,\\\"metric_operation\\\":\\\"maximize\\\",\\\"preprocess\\\":true}\", \"DataPrepJsonString\": \"{\\\\\\\"training_data\\\\\\\": {\\\\\\\"datasetId\\\\\\\": \\\\\\\"386f569b-55e5-476a-b65d-2f5a5a0b3a51\\\\\\\"}, \\\\\\\"datasets\\\\\\\": 0}\", \"EnableSubsampling\": null, \"runTemplate\": \"AutoML\", \"azureml.runsource\": \"automl\", \"display_task_type\": \"classification\", \"dependencies_versions\": \"{\\\"azureml-dataprep-native\\\": \\\"38.0.0\\\", \\\"azureml-dataprep\\\": \\\"4.10.8\\\", \\\"azureml-dataprep-rslex\\\": \\\"2.17.12\\\", \\\"azureml-train-automl-runtime\\\": \\\"1.51.0.post2\\\", \\\"azureml-train-automl-client\\\": \\\"1.51.0.post1\\\", \\\"azureml-training-tabular\\\": \\\"1.51.0.post1\\\", \\\"azureml-automl-runtime\\\": \\\"1.51.0.post1\\\", \\\"azureml-automl-core\\\": \\\"1.51.0.post1\\\", \\\"azureml-mlflow\\\": \\\"1.51.0\\\", \\\"azureml-datadrift\\\": \\\"1.51.0\\\", \\\"azureml-pipeline\\\": \\\"1.51.0\\\", \\\"azureml-contrib-dataset\\\": \\\"1.51.0\\\", \\\"azureml-contrib-notebook\\\": \\\"1.51.0\\\", \\\"azureml-accel-models\\\": \\\"1.51.0\\\", \\\"azureml-automl-dnn-nlp\\\": \\\"1.51.0\\\", \\\"azureml-pipeline-core\\\": \\\"1.51.0\\\", \\\"azureml-responsibleai\\\": \\\"1.51.0\\\", \\\"azureml-contrib-automl-pipeline-steps\\\": \\\"1.51.0\\\", \\\"azureml-pipeline-steps\\\": \\\"1.51.0\\\", \\\"azureml-core\\\": \\\"1.51.0\\\", \\\"azureml-contrib-reinforcementlearning\\\": \\\"1.51.0\\\", \\\"azureml-contrib-server\\\": \\\"1.51.0\\\", \\\"azureml-opendatasets\\\": \\\"1.51.0\\\", \\\"azureml-contrib-services\\\": \\\"1.51.0\\\", \\\"azureml-telemetry\\\": \\\"1.51.0\\\", \\\"azureml-train-restclients-hyperdrive\\\": \\\"1.51.0\\\", \\\"azureml-interpret\\\": \\\"1.51.0\\\", \\\"azureml-train-core\\\": \\\"1.51.0\\\", \\\"azureml-tensorboard\\\": \\\"1.51.0\\\", \\\"azureml-train\\\": \\\"1.51.0\\\", \\\"azureml-contrib-pipeline-steps\\\": \\\"1.51.0\\\", \\\"azureml-explain-model\\\": \\\"1.51.0\\\", \\\"azureml-cli-common\\\": \\\"1.51.0\\\", \\\"azureml-widgets\\\": \\\"1.51.0\\\", \\\"azureml-train-automl\\\": \\\"1.51.0\\\", \\\"azureml-defaults\\\": \\\"1.51.0\\\", \\\"azureml-contrib-fairness\\\": \\\"1.51.0\\\", \\\"azureml-sdk\\\": \\\"1.51.0\\\", \\\"azureml-dataset-runtime\\\": \\\"1.51.0\\\", \\\"azureml-inference-server-http\\\": \\\"0.8.4\\\"}\", \"_aml_system_scenario_identification\": \"Remote.Parent\", \"ClientType\": \"SDK\", \"PlatformVersion\": \"DPV1\", \"environment_cpu_name\": \"AzureML-AutoML\", \"environment_cpu_label\": \"prod\", \"environment_gpu_name\": \"AzureML-AutoML-GPU\", \"environment_gpu_label\": \"prod\", \"root_attribution\": \"automl\", \"attribution\": \"AutoML\", \"Orchestrator\": \"AutoML\", \"CancelUri\": \"https://southcentralus.api.azureml.ms/jasmine/v1.0/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourceGroups/aml-quickstarts-242066/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-242066/experimentids/97a7d825-4271-4b06-a0b0-13a316936862/cancel/AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a\", \"ClientSdkVersion\": null, \"snapshotId\": \"00000000-0000-0000-0000-000000000000\", \"SetupRunId\": \"AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_setup\", \"SetupRunContainerId\": \"dcid.AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_setup\", \"FeaturizationRunJsonPath\": \"featurizer_container.json\", \"FeaturizationRunId\": \"AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_featurize\"}, \"tags\": {\"model_explain_run\": \"best_run\", \"_aml_system_automl_run_workspace_id\": \"0fb57879-80ce-48b3-a3fe-56e3549beaf3\", \"_aml_system_azureml.automlComponent\": \"AutoML\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {}, \"log_groups\": [], \"run_duration\": \"0:08:55\", \"run_number\": \"1696090194\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_setup\", \"run_number\": 1696090207, \"metric\": null, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2023-09-30T16:15:20.567143Z\", \"end_time\": \"2023-09-30T16:18:13.704607Z\", \"created_time\": \"2023-09-30T16:10:07.213114Z\", \"created_time_dt\": \"2023-09-30T16:10:07.213114Z\", \"duration\": \"0:08:06\", \"iteration\": null, \"goal\": null, \"run_name\": \"Completed\", \"run_properties\": null}, {\"run_id\": \"AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_featurize\", \"run_number\": 1696090694, \"metric\": null, \"status\": \"Running\", \"run_type\": \"automl.featurization\", \"training_percent\": null, \"start_time\": \"2023-09-30T16:18:14.424858Z\", \"end_time\": \"\", \"created_time\": \"2023-09-30T16:18:14.001277Z\", \"created_time_dt\": \"2023-09-30T16:18:14.001277Z\", \"duration\": \"0:00:36\", \"iteration\": null, \"goal\": null, \"run_name\": \"Running\", \"run_properties\": null}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [{\"name\": \"experiment_status\", \"run_id\": \"AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a\", \"categories\": [0, 1, 2], \"series\": [{\"data\": [\"DatasetEvaluation\", \"FeaturesGeneration\", \"DatasetFeaturization\"]}]}, {\"name\": \"experiment_status_description\", \"run_id\": \"AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a\", \"categories\": [0, 1, 2], \"series\": [{\"data\": [\"Gathering dataset statistics.\", \"Generating features for the dataset.\", \"Beginning to fit featurizers and featurize the dataset.\"]}]}], \"run_logs\": \"Your job is submitted in Azure cloud and we are monitoring to get logs...\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.51.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1696090244113
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "remote_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl_experiment</td><td>AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-242066/workspaces/quick-starts-ws-242066&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nCurrent status: FeaturesGeneration. Generating features for the dataset.\nCurrent status: DatasetFeaturization. Beginning to fit featurizers and featurize the dataset.\nCurrent status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n"
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_run, fitted_model = remote_run.get_output()\n",
        "print(best_run)\n",
        "print(fitted_model)\n",
        "print(remote_run.get_metrics())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING:root:The version of the SDK does not match the version the model was trained on.\nWARNING:root:The consistency in the result may not be guaranteed.\nWARNING:root:Package:azureml-automl-core, training version:1.52.0.post1, current version:1.51.0.post1\nPackage:azureml-automl-runtime, training version:1.52.0.post1, current version:1.51.0.post1\nPackage:azureml-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-dataprep, training version:4.11.4, current version:4.10.8\nPackage:azureml-dataprep-rslex, training version:2.18.4, current version:2.17.12\nPackage:azureml-dataset-runtime, training version:1.52.0, current version:1.51.0\nPackage:azureml-defaults, training version:1.52.0, current version:1.51.0\nPackage:azureml-interpret, training version:1.52.0, current version:1.51.0\nPackage:azureml-mlflow, training version:1.52.0, current version:1.51.0\nPackage:azureml-pipeline-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-responsibleai, training version:1.52.0, current version:1.51.0\nPackage:azureml-telemetry, training version:1.52.0, current version:1.51.0\nPackage:azureml-train-automl-client, training version:1.52.0, current version:1.51.0.post1\nPackage:azureml-train-automl-runtime, training version:1.52.0, current version:1.51.0.post2\nPackage:azureml-train-core, training version:1.52.0, current version:1.51.0\nPackage:azureml-train-restclients-hyperdrive, training version:1.52.0, current version:1.51.0\nPackage:azureml-training-tabular, training version:1.52.0, current version:1.51.0.post1\nWARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run(Experiment: automl_experiment,\nId: AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_38,\nType: azureml.scriptrun,\nStatus: Completed)\nPipeline(memory=None,\n         steps=[('datatransformer',\n                 DataTransformer(enable_dnn=False, enable_feature_sweeping=True, feature_sweeping_config={}, feature_sweeping_timeout=86400, featurization_config=None, force_text_dnn=False, is_cross_validation=True, is_onnx_compatible=False, observer=None, task='classification', working_dir='/mnt/batch/tasks/shared/LS_root/mount...\n                 PreFittedSoftVotingClassifier(classification_labels=array([0, 1]), estimators=[('0', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('lightgbmclassifier', LightGBMClassifier(min_data_in_leaf=20, n_jobs=1, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=None))], verbose=False)), ('1', Pipeline(memory=None, steps=[('maxabsscaler', MaxAbsScaler(copy=True)), ('xgboostclassifier', XGBoostClassifier(n_jobs=1, problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, tree_method='auto'))], verbose=False)), ('14', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=None, max_features='auto', max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1, oob_score=False, random_state=None, verbose=0, warm_start=False))], verbose=False)), ('31', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('xgboostclassifier', XGBoostClassifier(booster='gbtree', colsample_bytree=0.9, eta=0.3, gamma=0, max_depth=6, max_leaves=0, n_estimators=50, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=1.1458333333333335, reg_lambda=0.4166666666666667, subsample=0.5, tree_method='auto'))], verbose=False)), ('22', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('xgboostclassifier', XGBoostClassifier(booster='gbtree', colsample_bytree=0.7, eta=0.3, gamma=0, max_depth=5, max_leaves=0, n_estimators=100, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=1.5625, reg_lambda=2.1875, subsample=0.7, tree_method='auto'))], verbose=False)), ('7', Pipeline(memory=None, steps=[('standardscalerwrapper', StandardScalerWrapper(copy=True, with_mean=False, with_std=False)), ('xgboostclassifier', XGBoostClassifier(booster='gbtree', colsample_bytree=0.5, eta=0.3, gamma=0, max_depth=10, max_leaves=255, n_estimators=10, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=0, reg_lambda=0.10416666666666667, subsample=0.7, tree_method='auto'))], verbose=False)), ('8', Pipeline(memory=None, steps=[('sparsenormalizer', Normalizer(copy=True, norm='max')), ('xgboostclassifier', XGBoostClassifier(booster='gbtree', colsample_bytree=0.8, eta=0.3, gamma=0.1, max_depth=10, max_leaves=63, n_estimators=10, n_jobs=1, objective='reg:logistic', problem_info=ProblemInfo(gpu_training_param_dict={'processing_unit_type': 'cpu'}), random_state=0, reg_alpha=1.25, reg_lambda=0.7291666666666667, subsample=1, tree_method='auto'))], verbose=False))], flatten_transform=None, weights=[0.6, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667, 0.06666666666666667]))],\n         verbose=False)\n{'experiment_status': ['DatasetEvaluation', 'FeaturesGeneration', 'DatasetFeaturization', 'DatasetFeaturizationCompleted', 'DatasetCrossValidationSplit', 'ModelSelection', 'BestRunExplainModel', 'ModelExplanationDataSetSetup', 'PickSurrogateModel', 'EngineeredFeatureExplanations', 'EngineeredFeatureExplanations', 'RawFeaturesExplanations', 'RawFeaturesExplanations', 'BestRunExplainModel'], 'experiment_status_description': ['Gathering dataset statistics.', 'Generating features for the dataset.', 'Beginning to fit featurizers and featurize the dataset.', 'Completed fit featurizers and featurizing the dataset.', 'Generating individually featurized CV splits.', 'Beginning model selection.', 'Best run model explanations started', 'Model explanations data setup completed', 'Choosing LightGBM as the surrogate model for explanations', 'Computation of engineered features started', 'Computation of engineered features completed', 'Computation of raw features started', 'Computation of raw features completed', 'Best run model explanations completed'], 'average_precision_score_micro': 0.9969246201941963, 'AUC_micro': 0.9970711053836195, 'precision_score_micro': 0.987665853170634, 'log_loss': 0.050894683742108905, 'precision_score_weighted': 0.9876481411498078, 'balanced_accuracy': 0.9791087922403822, 'AUC_macro': 0.9947772335754368, 'recall_score_macro': 0.9791087922403822, 'weighted_accuracy': 0.9925376254158368, 'f1_score_macro': 0.9828775286847286, 'average_precision_score_weighted': 0.9960623506821248, 'matthews_correlation': 0.9658670595095336, 'recall_score_weighted': 0.987665853170634, 'accuracy': 0.987665853170634, 'precision_score_macro': 0.9867893696581485, 'norm_macro_recall': 0.9582175844807642, 'f1_score_weighted': 0.987616416761122, 'average_precision_score_macro': 0.9941716976070808, 'recall_score_micro': 0.987665853170634, 'AUC_weighted': 0.9947772335754368, 'f1_score_micro': 0.987665853170634}\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1696091944864
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metric in best run\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "\n",
        "for metric_name in best_run_metrics:\n",
        "    metric = best_run_metrics[metric_name]\n",
        "    print(metric_name, metric)\n",
        "    \n",
        "print('\\nAUC_weighted of Best run',best_run_metrics['AUC_weighted'],sep='\\n')\n",
        "print(best_run)\n",
        "\n",
        "model_name = best_run.properties['model_name']\n",
        "model_name#Register the model\n",
        "model = remote_run.register_model(model_name=model_name)\n",
        "print(model.name, model.id, model.version, sep='\\t')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "f1_score_micro 0.987665853170634\nmatthews_correlation 0.9658670595095336\nprecision_score_macro 0.9867893696581485\naccuracy 0.987665853170634\nAUC_weighted 0.9947772335754368\nrecall_score_weighted 0.987665853170634\naverage_precision_score_macro 0.9941716976070808\nf1_score_macro 0.9828775286847286\nweighted_accuracy 0.9925376254158368\nrecall_score_micro 0.987665853170634\nrecall_score_macro 0.9791087922403822\nlog_loss 0.050894683742108905\nprecision_score_weighted 0.9876481411498078\nbalanced_accuracy 0.9791087922403822\nf1_score_weighted 0.987616416761122\nprecision_score_micro 0.987665853170634\nAUC_micro 0.9970711053836195\nnorm_macro_recall 0.9582175844807642\naverage_precision_score_micro 0.9969246201941963\naverage_precision_score_weighted 0.9960623506821248\nAUC_macro 0.9947772335754368\naccuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_38/accuracy_table\nconfusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_38/confusion_matrix\n\nAUC_weighted of Best run\n0.9947772335754368\nRun(Experiment: automl_experiment,\nId: AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_38,\nType: azureml.scriptrun,\nStatus: Completed)\nAutoML979f9db3e38\tAutoML979f9db3e38:2\t2\n"
        }
      ],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696094856727
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "model = remote_run.register_model(model_name='HR-best-automl-model')\n",
        "print(model.name, model.id, model.version, sep='\\t')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "HR-best-automl-model\tHR-best-automl-model:1\t1\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1696092035590
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598431435189
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deploy model\n",
        "from azureml.train.automl.run import AutoMLRun\n",
        "run_id= 'AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_38' #best run (from the previous cell output)\n",
        "best_run=AutoMLRun(experiment, run_id)\n",
        "best_run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "Run(Experiment: automl_experiment,\nId: AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_38,\nType: azureml.scriptrun,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl_experiment</td><td>AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_38</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/AutoML_979f9db3-ed3f-4ab4-8b4a-532c929e983a_38?wsid=/subscriptions/d7f39349-a66b-446e-aba6-0053c2cf1c11/resourcegroups/aml-quickstarts-242066/workspaces/quick-starts-ws-242066&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1696092086622
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrive model by name\n",
        "model = Model(ws, 'HR-best-automl-model')\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='quick-starts-ws-242066', subscription_id='d7f39349-a66b-446e-aba6-0053c2cf1c11', resource_group='aml-quickstarts-242066'), name=HR-best-automl-model, id=HR-best-automl-model:1, version=1, tags={}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1696092459372
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = best_run.get_environment()\n",
        "\n",
        "script_file = 'score.py'\n",
        "best_run.download_file('outputs/scoring_file_v_1_0_0.py', script_file)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696093234664
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.environment import Environment\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=script_file, environment=env)\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
        "                                                       memory_gb = 1)\n",
        "\n",
        "deploy_service_name= 'automl-model-deployment'\n",
        "service = Model.deploy(ws,deploy_service_name,  [model], inference_config, deployment_config)\n",
        "\n",
        "service.wait_for_deployment(show_output = True)\n",
        "\n",
        "scoring_uri = service.scoring_uri\n",
        "\n",
        "print(\"State: \",service.state)\n",
        "print(\"\\nScoring URI: \", scoring_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2023-09-30 17:00:50+00:00 Creating Container Registry if not exists..\n2023-09-30 17:10:50+00:00 Registering the environment.\n2023-09-30 17:10:51+00:00 Use the existing image.\n2023-09-30 17:10:52+00:00 Submitting deployment to compute..\n2023-09-30 17:10:57+00:00 Checking the status of deployment automl-model-deployment..\n2023-09-30 17:13:42+00:00 Checking the status of inference endpoint automl-model-deployment.\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nState:  Healthy\n\nScoring URI:  http://bfd454ae-2063-4b1b-a45b-82f097e5a0e7.southcentralus.azurecontainer.io/score\n"
        }
      ],
      "execution_count": 22,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696094072050
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Enable application insights\n",
        "service.update(enable_app_insights=True)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696094083940
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test service\n",
        "%run endpoint_v2.py"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "HTTPConnectionPool(host='afcc82ca-85bd-4d21-baf4-835954f56321.westus2.azurecontainer.io', port=80): Max retries exceeded with url: /score (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f919dc8b580>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/util/connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m six\u001b[38;5;241m.\u001b[39mraise_from(\n\u001b[1;32m     69\u001b[0m         LocationParseError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m host), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/socket.py:918\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    917\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 918\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    919\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno -2] Name or service not known",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connectionpool.py:415\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    243\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1255\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1255\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1301\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1301\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1250\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:1010\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1010\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m \n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/http/client.py:950\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7f919dc8b580>: Failed to establish a new connection: [Errno -2] Name or service not known",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/connectionpool.py:798\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    796\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 798\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/urllib3/util/retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='afcc82ca-85bd-4d21-baf4-835954f56321.westus2.azurecontainer.io', port=80): Max retries exceeded with url: /score (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f919dc8b580>: Failed to establish a new connection: [Errno -2] Name or service not known'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/notebook242066/code/Users/odl_user_242066/starter_file/endpoint_v2.py:49\u001b[0m\n\u001b[1;32m     46\u001b[0m headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Make the request and display the response\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscoring_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(resp\u001b[38;5;241m.\u001b[39mjson())\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='afcc82ca-85bd-4d21-baf4-835954f56321.westus2.azurecontainer.io', port=80): Max retries exceeded with url: /score (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f919dc8b580>: Failed to establish a new connection: [Errno -2] Name or service not known'))"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696094686064
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "data_sample = df.sample(2)\n",
        "y_true = data_sample.pop('left')\n",
        "sample_json = json.dumps({'data':data_sample.to_dict(orient='records')})\n",
        "print(sample_json)\n",
        "output = service.run(sample_json)\n",
        "print(output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\"data\": [{\"satisfaction_level\": 0.63, \"last_evaluation\": 0.66, \"number_project\": 4, \"average_montly_hours\": 157, \"time_spend_company\": 2, \"Work_accident\": 0, \"promotion_last_5years\": 0, \"Department\": \"support\", \"salary\": \"medium\"}, {\"satisfaction_level\": 0.86, \"last_evaluation\": 0.85, \"number_project\": 5, \"average_montly_hours\": 267, \"time_spend_company\": 5, \"Work_accident\": 0, \"promotion_last_5years\": 0, \"Department\": \"sales\", \"salary\": \"medium\"}]}\n{\"result\": [0, 0]}\n"
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696094758259
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nService Logs:\\n\",service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nService Logs:\n 2023-09-30T17:13:32,906269300+00:00 - rsyslog/run \n2023-09-30T17:13:32,913717500+00:00 - gunicorn/run \n2023-09-30T17:13:32,919853700+00:00 | gunicorn/run | \n2023-09-30T17:13:32,921847900+00:00 | gunicorn/run | ###############################################\n2023-09-30T17:13:32,928967600+00:00 | gunicorn/run | AzureML Container Runtime Information\n2023-09-30T17:13:32,931057600+00:00 | gunicorn/run | ###############################################\n2023-09-30T17:13:32,936710300+00:00 | gunicorn/run | \n2023-09-30T17:13:32,944471600+00:00 | gunicorn/run | \n2023-09-30T17:13:32,947849800+00:00 - nginx/run \n2023-09-30T17:13:32,954470100+00:00 | gunicorn/run | AzureML image information: openmpi4.1.0-ubuntu20.04, Materializaton Build:20230628.v2\n2023-09-30T17:13:32,956130700+00:00 | gunicorn/run | \n2023-09-30T17:13:32,963816600+00:00 | gunicorn/run | \n2023-09-30T17:13:32,970114400+00:00 | gunicorn/run | PATH environment variable: /azureml-envs/azureml-automl/bin:/opt/miniconda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n2023-09-30T17:13:32,974647400+00:00 | gunicorn/run | PYTHONPATH environment variable: \n2023-09-30T17:13:32,979984000+00:00 | gunicorn/run | \n2023-09-30T17:13:34,543149300+00:00 | gunicorn/run | CONDAPATH environment variable: /opt/miniconda\n\n# conda environments:\n#\n                         /azureml-envs/azureml-automl\nbase                     /opt/miniconda\n\n2023-09-30T17:13:36,523697530+00:00 | gunicorn/run | \n2023-09-30T17:13:36,525919334+00:00 | gunicorn/run | Pip Dependencies (before dynamic installation)\n\nadal==1.2.7\napplicationinsights==0.11.10\narch==5.3.1\nargcomplete==2.1.2\nargon2-cffi==21.3.0\nargon2-cffi-bindings==21.2.0\nasttokens==2.2.1\nattrs==23.1.0\nazure-common==1.1.28\nazure-core==1.27.1\nazure-graphrbac==0.61.1\nazure-identity==1.13.0\nazure-mgmt-authorization==3.0.0\nazure-mgmt-containerregistry==10.1.0\nazure-mgmt-core==1.4.0\nazure-mgmt-keyvault==10.2.2\nazure-mgmt-resource==22.0.0\nazure-mgmt-storage==21.0.0\nazure-storage-blob==12.13.0\nazure-storage-queue==12.6.0\nazureml-automl-core==1.52.0.post1\nazureml-automl-runtime==1.52.0.post1\nazureml-core==1.52.0\nazureml-dataprep==4.11.4\nazureml-dataprep-native==38.0.0\nazureml-dataprep-rslex==2.18.4\nazureml-dataset-runtime==1.52.0\nazureml-defaults==1.52.0\nazureml-inference-server-http==0.8.4\nazureml-interpret==1.52.0\nazureml-mlflow==1.52.0\nazureml-pipeline-core==1.52.0\nazureml-responsibleai==1.52.0\nazureml-telemetry==1.52.0\nazureml-train-automl-client==1.52.0\nazureml-train-automl-runtime==1.52.0\nazureml-train-core==1.52.0\nazureml-train-restclients-hyperdrive==1.52.0\nazureml-training-tabular==1.52.0\nbackcall==0.2.0\nbackports.tempfile==1.0\nbackports.weakref==1.0.post1\nbcrypt==4.0.1\nbeautifulsoup4==4.12.2\nbleach==6.0.0\nbokeh==2.4.3\nboto==2.49.0\nboto3==1.20.19\nbotocore==1.23.19\nBrotli @ file:///home/conda/feedstock_root/build_artifacts/brotli-split_1687884021435/work\ncachetools==5.3.1\ncertifi==2023.5.7\ncffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1671179356964/work\ncharset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1678108872112/work\nclick==8.1.4\ncloudpickle @ file:///home/conda/feedstock_root/build_artifacts/cloudpickle_1598400192773/work\ncmdstanpy==0.9.5\ncontextlib2==21.6.0\ncontourpy==1.1.0\nconvertdate @ file:///home/conda/feedstock_root/build_artifacts/convertdate_1642883757836/work\ncryptography==41.0.0\ncycler==0.11.0\nCython==0.29.17\ndask==2023.2.0\ndatabricks-cli==0.17.7\ndataclasses==0.6\ndebugpy==1.6.7\ndecorator==5.1.1\ndefusedxml==0.7.1\ndice-ml==0.9\ndill==0.3.6\ndistributed==2023.2.0\ndistro==1.8.0\ndocker==6.1.3\ndotnetcore2==3.1.23\neconml==0.14.1\nentrypoints==0.4\nephem==4.1.4\nerroranalysis==0.4.4\nexecuting==1.2.0\nfairlearn==0.8.0\nfastjsonschema==2.17.1\nfbprophet==0.7.1\nfire==0.5.0\nFlask==2.2.5\nFlask-Cors==3.0.10\nflatbuffers==23.5.26\nfonttools==4.40.0\nfsspec==2023.6.0\nfusepy==3.0.1\ngensim==3.8.3\ngitdb==4.0.10\nGitPython==3.1.31\ngoogle-api-core==2.11.1\ngoogle-auth==2.21.0\ngoogleapis-common-protos==1.59.1\ngunicorn==20.1.0\nh5py==3.9.0\nholidays @ file:///home/conda/feedstock_root/build_artifacts/holidays_1595448845196/work\nhumanfriendly==10.0\nidna @ file:///home/conda/feedstock_root/build_artifacts/idna_1663625384323/work\nimportlib-metadata==6.8.0\nimportlib-resources==5.13.0\ninference-schema==1.5.1\ninterpret-community==0.29.0\ninterpret-core==0.3.2\nipykernel==6.8.0\nipython==8.12.2\nipython-genutils==0.2.0\nisodate==0.6.1\nitsdangerous==2.1.2\njedi==0.18.2\njeepney==0.8.0\nJinja2==3.1.2\njmespath==0.10.0\njoblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1663332044897/work\njsonpickle==3.0.1\njsonschema==4.18.0\njsonschema-specifications==2023.6.1\njupyter_client==7.4.9\njupyter_core==5.3.1\njupyterlab-pygments==0.2.2\nkeras2onnx==1.6.0\nkiwisolver==1.4.4\nknack==0.10.1\nkorean-lunar-calendar @ file:///home/conda/feedstock_root/build_artifacts/korean_lunar_calendar_1663341251025/work\nlightgbm==3.2.1\nllvmlite==0.38.1\nlocket==1.0.0\nLunarCalendar==0.0.9\nMarkupSafe==2.1.2\nmatplotlib==3.7.2\nmatplotlib-inline==0.1.6\nmistune==3.0.1\nml-wrappers==0.4.11\nmlflow-skinny==2.4.1\nmltable==1.4.1\nmsal==1.22.0\nmsal-extensions==1.0.0\nmsgpack==1.0.5\nmsrest==0.7.1\nmsrestazure==0.6.4\nnbclient==0.8.0\nnbconvert==7.6.0\nnbformat==5.9.0\nndg-httpsclient==0.5.1\nnest-asyncio==1.5.6\nnetworkx==2.5\nnotebook==6.4.9\nnumba==0.55.2\nnumpy==1.22.3\noauthlib==3.2.2\nonnx==1.13.1\nonnxconverter-common==1.6.0\nonnxmltools==1.4.1\nonnxruntime==1.11.1\nopencensus==0.11.2\nopencensus-context==0.1.3\nopencensus-ext-azure==1.1.9\npackaging==23.0\npandas==1.1.5\npandocfilters==1.5.0\nparamiko==3.2.0\nparso==0.8.3\npartd==1.4.0\npathspec==0.11.1\npatsy==0.5.3\npexpect==4.8.0\npickleshare==0.7.5\nPillow==10.0.0\npkginfo==1.9.6\npkgutil_resolve_name==1.3.10\nplatformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1688739404342/work\npmdarima==1.8.0\npooch @ file:///home/conda/feedstock_root/build_artifacts/pooch_1679580333621/work\nportalocker==2.7.0\nprometheus-client==0.17.0\nprompt-toolkit==3.0.39\nproperty-cached==1.6.4\nprotobuf==3.20.3\npsutil @ file:///home/conda/feedstock_root/build_artifacts/psutil_1681775007745/work\nptyprocess==0.7.0\npure-eval==0.2.2\npy-cpuinfo==5.0.0\npyarrow==9.0.0\npyasn1==0.5.0\npyasn1-modules==0.3.0\npycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\npydantic==1.10.11\nPygments==2.15.1\nPyJWT==2.7.0\nPyMeeus @ file:///home/conda/feedstock_root/build_artifacts/pymeeus_1670868433998/work\nPyNaCl==1.5.0\npyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1685514481738/work\npyparsing==3.0.9\nPySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1661604839144/work\npystan==2.19.1.1\npython-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\npytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1680088766131/work\nPyYAML==6.0\npyzmq==25.1.0\nraiutils==0.4.0\nreferencing==0.29.1\nrequests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work\nrequests-oauthlib==1.3.1\nresponsibleai==0.28.0\nrpds-py==0.8.8\nrsa==4.9\ns3transfer==0.5.2\nscikit-learn==0.22.1\nscipy==1.5.3\nSecretStorage==3.3.3\nsemver==2.13.0\nSend2Trash==1.8.2\nsetuptools-git==1.2\nshap==0.41.0\nsix @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\nskl2onnx==1.4.9\nsklearn-pandas==1.7.0\nslicer==0.0.7\nsmart-open==1.9.0\nsmmap==5.0.0\nsortedcontainers==2.4.0\nsoupsieve==2.4.1\nsparse==0.14.0\nsqlparse==0.4.4\nstack-data==0.6.2\nstatsmodels==0.11.1\ntabulate==0.9.0\ntblib==2.0.0\ntermcolor==2.3.0\nterminado==0.17.1\ntinycss2==1.2.1\ntoolz==0.12.0\ntornado==6.3.2\ntqdm==4.65.0\ntraitlets==5.9.0\ntyping_extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1688315532570/work\nurllib3==1.26.16\nwcwidth==0.2.6\nwebencodings==0.5.1\nwebsocket-client==1.6.1\nWerkzeug==2.3.6\nwrapt==1.12.1\nxgboost==1.3.3\nzict==3.0.0\nzipp==3.15.0\n\n2023-09-30T17:13:39,801419565+00:00 | gunicorn/run | \n2023-09-30T17:13:39,806998075+00:00 | gunicorn/run | ###############################################\n2023-09-30T17:13:39,820298200+00:00 | gunicorn/run | Checking if the Python package azureml-inference-server-http is installed\n2023-09-30T17:13:39,828378614+00:00 | gunicorn/run | ###############################################\n2023-09-30T17:13:39,836612129+00:00 | gunicorn/run | \n2023-09-30T17:13:46,884316775+00:00 | gunicorn/run | \n2023-09-30T17:13:46,891415221+00:00 | gunicorn/run | ###############################################\n2023-09-30T17:13:46,902459893+00:00 | gunicorn/run | AzureML Inference Server\n2023-09-30T17:13:46,909848741+00:00 | gunicorn/run | ###############################################\n2023-09-30T17:13:46,914016168+00:00 | gunicorn/run | \n2023-09-30T17:13:52,507236833+00:00 | gunicorn/run | Starting AzureML Inference Server HTTP.\n2023-09-30 17:13:53,247 I [76] azmlinfsrv - Loaded logging config from /azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/logging.json\n2023-09-30 17:13:53,912 I [76] gunicorn.error - Starting gunicorn 20.1.0\n2023-09-30 17:13:53,915 I [76] gunicorn.error - Listening at: http://0.0.0.0:31311 (76)\n2023-09-30 17:13:53,915 I [76] gunicorn.error - Using worker: sync\n2023-09-30 17:13:53,928 I [167] gunicorn.error - Booting worker with pid: 167\n\nAzure ML Inferencing HTTP server v0.8.4\n\n\nServer Settings\n---------------\nEntry Script Name: /var/azureml-app/main.py\nModel Directory: /var/azureml-app/azureml-models/HR-best-automl-model/1\n/azureml-envs/azureml-automl/lib/python3.8/site-packages/azureml_inference_server_http/server/config.py:51: FutureWarning: aliases are no longer used by BaseSettings to define which environment variables to read. Instead use the \"env\" field setting. See https://pydantic-docs.helpmanual.io/usage/settings/#environment-variable-names\n  class AMLInferenceServerConfig(pydantic.BaseSettings):\nConfig File: None\nWorker Count: 1\nWorker Timeout (seconds): 300\nServer Port: 31311\nHealth Port: 31311\nApplication Insights Enabled: false\nApplication Insights Key: None\nInferencing HTTP server version: azmlinfsrv/0.8.4\nCORS for the specified origins: None\nCreate dedicated endpoint for health: None\n\n\nServer Routes\n---------------\nLiveness Probe: GET   127.0.0.1:31311/\nScore:          POST  127.0.0.1:31311/score\n\n2023-09-30 17:13:55,672 I [167] azmlinfsrv - AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\nInitializing logger\n2023-09-30 17:13:55,676 I [167] azmlinfsrv - Starting up app insights client\n2023-09-30 17:13:57,650 I [167] azmlinfsrv.user_script - Found driver script at /var/azureml-app/main.py and the score script at /var/azureml-app/score.py\n2023-09-30 17:13:57,651 I [167] azmlinfsrv.user_script - run() is decorated with @input_schema. Server will invoke it with the following arguments: data, method.\n2023-09-30 17:13:57,651 I [167] azmlinfsrv.user_script - Invoking user's init function\nERROR:fbprophet.plot:Importing plotly failed. Interactive plots will not work.\n2023-09-30 17:14:18,204 I [167] azmlinfsrv.user_script - Users's init has completed successfully\n2023-09-30 17:14:18,285 I [167] azmlinfsrv.swagger - Swaggers are prepared for the following versions: [2, 3, 3.1].\n2023-09-30 17:14:18,287 I [167] azmlinfsrv - Scoring timeout is set to 60000\n2023-09-30 17:14:18,294 W [167] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-30 17:14:18,296 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:18 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-30 17:14:18,300 W [167] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-30 17:14:18,301 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:18 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-30 17:14:18,302 W [167] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-30 17:14:18,302 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:18 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-30 17:14:18,303 W [167] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-30 17:14:18,309 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:18 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-30 17:14:18,313 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:18 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"curl/7.58.0\"\n2023-09-30 17:14:28,671 W [167] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-30 17:14:28,673 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:28 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-30 17:14:28,697 W [167] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-30 17:14:28,698 I [167] azmlinfsrv - GET /swagger.json 200 1.096ms 3393\n2023-09-30 17:14:28,699 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:28 +0000] \"GET /swagger.json HTTP/1.0\" 200 3393 \"-\" \"Go-http-client/1.1\"\n2023-09-30 17:14:31,636 W [167] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-30 17:14:31,638 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:31 +0000] \"GET / HTTP/1.0\" 200 7 \"-\" \"Go-http-client/1.1\"\n2023-09-30 17:14:31,655 W [167] azmlinfsrv - x-ms-request-id header has been deprecated and will be removed from future versions of the server. Please use x-ms-client-request-id.\n2023-09-30 17:14:31,661 I [167] azmlinfsrv - GET /swagger.json 200 7.199ms 3393\n2023-09-30 17:14:31,663 I [167] gunicorn.access - 127.0.0.1 - - [30/Sep/2023:17:14:31 +0000] \"GET /swagger.json HTTP/1.0\" 200 3393 \"-\" \"Go-http-client/1.1\"\n\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1696094073767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete the endpoint\n",
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once all the work has been completed, we proceed to delete the cluster."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete the cluster\n",
        "cpu_cluster.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check status of the cluster for deletion \n",
        "cpu_cluster"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Submission Checklist**\n",
        "- I have registered the model.\n",
        "- I have deployed the model with the best accuracy as a webservice.\n",
        "- I have tested the webservice by sending a request to the model endpoint.\n",
        "- I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- I have taken a screenshot showing the model endpoint as active.\n",
        "- The project includes a file containing the environment details.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}